{"cells":[{"cell_type":"code","execution_count":null,"id":"0863f387-cae2-44e2-a178-a8c8282bbf69","metadata":{"id":"0863f387-cae2-44e2-a178-a8c8282bbf69","executionInfo":{"status":"aborted","timestamp":1747123188320,"user_tz":-345,"elapsed":5,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["import torch\n","import torchvision\n","from torchvision.models.detection import fasterrcnn_resnet50_fpn\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","import json\n","from tqdm import tqdm\n","import random"]},{"cell_type":"code","execution_count":10,"id":"jrroBwMyrwd0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4132,"status":"ok","timestamp":1747123656779,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"},"user_tz":-345},"id":"jrroBwMyrwd0","outputId":"6705436a-30b2-4b0e-de92-7d660087a824"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":11,"id":"SmVA7k1MsxQn","metadata":{"id":"SmVA7k1MsxQn","executionInfo":{"status":"ok","timestamp":1747123659236,"user_tz":-345,"elapsed":305,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["import torch\n","from torchvision.transforms import ToTensor\n","from PIL import Image\n","import os\n","import json\n","\n","# Load COCO-style annotations\n","with open(\"/content/drive/MyDrive/DocumentAnalysisRCNN/annotations.json\") as f:\n","    coco_data = json.load(f)\n","\n","# Extract image IDs\n","image_ids = [img['id'] for img in coco_data['images']]\n","\n","# Path to your images directory\n","images_dir = \"/content/drive/MyDrive/DocumentAnalysisRCNN/images\"\n","\n","# Custom COCO Dataset class\n","class COCODataset(torch.utils.data.Dataset):\n","    def __init__(self, images_dir, coco_data, image_ids, transform=None):\n","        self.images_dir = images_dir\n","        self.coco_data = coco_data\n","        self.image_ids = image_ids\n","        self.transform = transform\n","\n","        self.image_id_to_info = {img['id']: img for img in coco_data['images']}\n","        self.image_id_to_anns = {}\n","        for ann in coco_data['annotations']:\n","            self.image_id_to_anns.setdefault(ann['image_id'], []).append(ann)\n","\n","        self.categories = {cat['id']: cat['name'] for cat in coco_data['categories']}\n","\n","    def __len__(self):\n","        return len(self.image_ids)\n","\n","    def __getitem__(self, idx):\n","        img_id = self.image_ids[idx]\n","        image_info = self.image_id_to_info[img_id]\n","        img_path = os.path.join(self.images_dir, image_info['file_name'])\n","        img = Image.open(img_path).convert(\"RGB\")\n","        img_tensor = ToTensor()(img)\n","\n","        anns = self.image_id_to_anns.get(img_id, [])\n","\n","        # Skip if there are no annotations\n","        if len(anns) == 0:\n","            return self.__getitem__((idx + 1) % len(self))\n","\n","        boxes, labels, areas, iscrowd = [], [], [], []\n","\n","        for ann in anns:\n","            x, y, w, h = ann['bbox']\n","            boxes.append([x, y, x + w, y + h])\n","            labels.append(ann['category_id'])\n","            areas.append(ann['area'])\n","            iscrowd.append(ann.get('iscrowd', 0))\n","\n","        target = {\n","            'boxes': torch.tensor(boxes, dtype=torch.float32),\n","            'labels': torch.tensor(labels, dtype=torch.int64),\n","            'image_id': torch.tensor([img_id]),\n","            'area': torch.tensor(areas, dtype=torch.float32),\n","            'iscrowd': torch.tensor(iscrowd, dtype=torch.int64)\n","        }\n","\n","        return img_tensor, target\n","\n","# Instantiate the dataset\n","dataset = COCODataset(images_dir, coco_data, image_ids)"]},{"cell_type":"code","execution_count":12,"id":"c161a46b-b3bf-432b-8ec2-05f8986f9f74","metadata":{"id":"c161a46b-b3bf-432b-8ec2-05f8986f9f74","executionInfo":{"status":"ok","timestamp":1747123677111,"user_tz":-345,"elapsed":1576,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["# === Load dataset ===\n","coco_json_path = \"/content/drive/MyDrive/DocumentAnalysisRCNN/annotations.json\"\n","images_dir = \"/content/drive/MyDrive/DocumentAnalysisRCNN/images\"\n","\n","with open(coco_json_path) as f:\n","    coco_data = json.load(f)\n","\n","# === Split image IDs ===\n","all_image_ids = [img['id'] for img in coco_data['images']]\n","random.shuffle(all_image_ids)\n","\n","split_idx = int(0.8 * len(all_image_ids))\n","train_ids = all_image_ids[:split_idx]\n","val_ids = all_image_ids[split_idx:]\n"]},{"cell_type":"code","execution_count":13,"id":"e9d839b9-bdf9-4b04-97f4-ec0dcd0df757","metadata":{"id":"e9d839b9-bdf9-4b04-97f4-ec0dcd0df757","executionInfo":{"status":"ok","timestamp":1747123678297,"user_tz":-345,"elapsed":4,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["train_dataset = COCODataset(images_dir, coco_data, train_ids)\n","val_dataset = COCODataset(images_dir, coco_data, val_ids)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=2, shuffle=False, collate_fn=lambda x: tuple(zip(*x)))"]},{"cell_type":"code","execution_count":14,"id":"c77c35ba-294f-4ee7-9c65-642d39ed5798","metadata":{"executionInfo":{"elapsed":821,"status":"ok","timestamp":1747123681473,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"},"user_tz":-345},"id":"c77c35ba-294f-4ee7-9c65-642d39ed5798"},"outputs":[],"source":["model = fasterrcnn_resnet50_fpn(pretrained=True)\n","\n","num_classes = len(train_dataset.categories) + 1  # +1 for background\n","in_features = model.roi_heads.box_predictor.cls_score.in_features\n","model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)"]},{"cell_type":"code","execution_count":15,"id":"64ad6197-866d-4b5a-99bc-8340e81553ca","metadata":{"id":"64ad6197-866d-4b5a-99bc-8340e81553ca","executionInfo":{"status":"ok","timestamp":1747123682964,"user_tz":-345,"elapsed":4,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["params = [p for p in model.parameters() if p.requires_grad]\n","optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)"]},{"cell_type":"code","execution_count":null,"id":"d97fea9d-3cc4-47c9-a5bf-730e8a084de9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d97fea9d-3cc4-47c9-a5bf-730e8a084de9","outputId":"6dfa7c71-3813-4c46-a2ea-3567c3e4b78a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Epoch 1 Training:   3%|â–Ž         | 13/400 [13:39<6:17:28, 58.52s/it]"]}],"source":["num_epochs = 10\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss = 0\n","\n","    for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\"):\n","        images = [img.to(device) for img in images]\n","        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n","\n","        loss_dict = model(images, targets)\n","        losses = sum(loss for loss in loss_dict.values())\n","\n","        optimizer.zero_grad()\n","        losses.backward()\n","        optimizer.step()\n","\n","        total_loss += losses.item()\n","\n","    print(f\"Epoch {epoch+1}, Training Loss: {total_loss/len(train_loader):.4f}\")"]},{"cell_type":"code","execution_count":null,"id":"77fb0aa7-b458-4283-ba38-a5a700478bfc","metadata":{"id":"77fb0aa7-b458-4283-ba38-a5a700478bfc","executionInfo":{"status":"aborted","timestamp":1747123188098,"user_tz":-345,"elapsed":0,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["torch.save(model.state_dict(), \"Document Analysis.pth\")\n","print(\"Document Analysis.pth\")"]},{"cell_type":"code","execution_count":null,"id":"429e1d4e-8585-43ea-bf60-9a86660dd356","metadata":{"id":"429e1d4e-8585-43ea-bf60-9a86660dd356","executionInfo":{"status":"aborted","timestamp":1747123188113,"user_tz":-345,"elapsed":0,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"a23bffee-ac02-4abf-a1d7-86c4cba825fd","metadata":{"id":"a23bffee-ac02-4abf-a1d7-86c4cba825fd"},"outputs":[],"source":["import os\n","import random\n","import shutil\n","\n","# Set your image directory path\n","images_dir = \"/content/drive/MyDrive/DocumentAnalysisRCNN/images\"  # Update with your path\n","annotations_dir = \"/content/drive/MyDrive/DocumentAnalysisRCNN/annotations.json\"  # Update with your annotations directory path\n","\n","# List all image files in the directory (change to the correct extension if needed)\n","all_images = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]\n","\n","# Select 1000 random images\n","num_images_to_keep = 1000\n","images_to_keep = random.sample(all_images, num_images_to_keep)\n","\n","# Delete images that are not in the selected set\n","images_to_delete = set(all_images) - set(images_to_keep)\n","\n","# Delete extra images from the images directory\n","for image in images_to_delete:\n","    image_path = os.path.join(images_dir, image)\n","    if os.path.exists(image_path):\n","        os.remove(image_path)  # Delete the image file\n","        print(f\"Deleted {image_path}\")\n","\n","# Optional: Delete corresponding annotation files if you want to remove them too\n","for image in images_to_delete:\n","    annotation_file = image.replace('.jpg', '.xml').replace('.png', '.xml')  # Assuming XML annotations\n","    annotation_path = os.path.join(annotations_dir, annotation_file)\n","    if os.path.exists(annotation_path):\n","        os.remove(annotation_path)  # Delete the annotation file\n","        print(f\"Deleted {annotation_path}\")\n","\n","print(f\"Kept {num_images_to_keep} images and deleted the rest.\")\n"]},{"cell_type":"code","execution_count":null,"id":"07b69ce5-5987-41fb-972b-298645447076","metadata":{"id":"07b69ce5-5987-41fb-972b-298645447076"},"outputs":[],"source":["import os\n","import json\n","\n","# Set your image directory and JSON file path\n","images_dir = \"./images\"  # Update with your image directory path\n","json_file_path = \"./annotations.json\"  # Update with your JSON file path\n","\n","# List all remaining image files in the directory (change to correct extension if needed)\n","existing_images = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]\n","\n","# Load the existing JSON file\n","with open(json_file_path, 'r') as json_file:\n","    data = json.load(json_file)\n","\n","# Create a set of filenames for fast lookups\n","existing_image_filenames = set(existing_images)\n","\n","# Filter images and annotations to keep only those that are in the existing_images list\n","updated_images = [img for img in data['images'] if img['file_name'] in existing_image_filenames]\n","updated_annotations = [anno for anno in data['annotations'] if anno['image_id'] in [img['id'] for img in updated_images]]\n","\n","# Create the updated JSON structure\n","updated_data = {\n","    \"info\": data[\"info\"],\n","    \"licenses\": data[\"licenses\"],\n","    \"images\": updated_images,\n","    \"annotations\": updated_annotations,\n","    \"categories\": data[\"categories\"]\n","}\n","\n","# Save the updated JSON file\n","with open(json_file_path, 'w') as json_file:\n","    json.dump(updated_data, json_file, indent=4)\n","\n","print(f\"Updated JSON file to reflect only the remaining {len(updated_images)} images and their annotations.\")\n"]},{"cell_type":"code","execution_count":null,"id":"524d95e0-2b68-4794-baf0-3dbce90dddeb","metadata":{"id":"524d95e0-2b68-4794-baf0-3dbce90dddeb","executionInfo":{"status":"aborted","timestamp":1747123188209,"user_tz":-345,"elapsed":17,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":["pip install torch torchvision torchaudio\n"]},{"cell_type":"code","execution_count":null,"id":"4fbd0769-21af-4a30-998d-390b27ae964e","metadata":{"id":"4fbd0769-21af-4a30-998d-390b27ae964e","executionInfo":{"status":"aborted","timestamp":1747123188212,"user_tz":-345,"elapsed":0,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"f6461532-f870-40aa-a44c-d46409cf4d9f","metadata":{"id":"f6461532-f870-40aa-a44c-d46409cf4d9f","executionInfo":{"status":"aborted","timestamp":1747123188221,"user_tz":-345,"elapsed":7,"user":{"displayName":"Aakriti Dahal","userId":"10755187098071094797"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":5}